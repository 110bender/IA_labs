{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travaux Pratiques Intelligence Artificielle: Lab2\n",
    "\n",
    "Neural Networks avec Pytorch ü§ñ üôå.\n",
    "\n",
    "## Objectifs du TP:\n",
    "\n",
    "> **Se Familiariser avec Pytorch** \n",
    "\n",
    "> **Comprendre le processus d'apprentissage d'un r√©seau de neurones**\n",
    "\n",
    "> **Cr√©er un r√©seau de neurones (feed-forward multilayers NN) avec Pytorch**\n",
    "\n",
    "\n",
    "\n",
    "<br></br>\n",
    "_Besoin d'aide? Laisser moi un Commentaire sur Teams_\n",
    "\n",
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Introduction √† Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch est une librairie open source Python, developp√©e par AI Research lab (FAIR) de Facebook et publi√©e en ligne en Sept. 2016. Elle permet d'effectuer les calculs tensoriels n√©cessaires notamment pour l'apprentissage profond (deep learning).   \n",
    "\n",
    "Pytorch permet une impl√©mentation et un apprentissage facile des r√©seaux de neurones (NN). Elle est tr√®s proche de la syntaxe de Python, d'ailleurs il est m√™me possible d'int√©grer des blocs if else dans un code NN. Elle a une riche communaut√© et une documentation actualis√©e (compar√©e √† tensorflow). D'autant plus qu'elle est tr√®s utilis√©e par les chercheurs, ce qui garantie l'impl√©mentation des nouveaux mod√®les sur Pytorch.\n",
    "\n",
    "Vous pouvez installer Pytorch √† partir d'un terminal ou au niveau de ce jupyter en ex√©cutant la cellule ci-dessous. \n",
    "\n",
    "**N.B.** Si vous avez des inconsistences au niveau de l'installation, pensez √† cr√©er un environnement sp√©cifique pour ce TP.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Afin de mener √† bien les impl√©mentations des NN, Pytorch fournit l'objet **Tensor**. Un tensor sur Pytorch a les m√™mes fonctions et syntaxe qu'un numpy array mais est optimis√© pour GPU. D'autant plus que son backend C++ permet √† Pytorch d'√™tre beaucoup plus performante et rapide que numpy. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "# Importer torch\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# cr√©er une matrice identit√© de taille 4x4\n",
    "eye4 = torch.eye(4)\n",
    "print(eye4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5776, 0.7423, 0.0033],\n",
      "        [0.0299, 0.5667, 0.3081],\n",
      "        [0.6258, 0.8117, 0.7609],\n",
      "        [0.8840, 0.2980, 0.3390]])\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un tensor avec des valeurs al√©atoires d'une taille de votre choix\n",
    "x = torch.rand(4,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5776, 0.7423, 0.0033, 0.0299],\n",
       "        [0.5667, 0.3081, 0.6258, 0.8117],\n",
       "        [0.7609, 0.8840, 0.2980, 0.3390]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changer la forme de votre tensor \n",
    "x.view(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher la taille, la forme,\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# et le type des √©l√©ments de votre tensor\n",
    "x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = torch.transpose(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.5776, 20.7423, 20.0033],\n",
       "        [20.0299, 20.5667, 20.3081],\n",
       "        [20.6258, 20.8117, 20.7609],\n",
       "        [20.8840, 20.2980, 20.3390]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajouter une constante fixe √† l'ensemble des √©l√©ments du tensor\n",
    "torch.add(x, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8846, 0.4389, 0.9665, 0.7330],\n",
       "        [0.4389, 0.4170, 0.7131, 0.2997],\n",
       "        [0.9665, 0.7131, 1.6294, 1.0530],\n",
       "        [0.7330, 0.2997, 1.0530, 0.9852]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplier votre tensor par sa transpos√© (multiplication matricielle, pas element-wise)\n",
    "torch.mm(x,xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5667) tensor(0.3390)\n"
     ]
    }
   ],
   "source": [
    "# Avec quelques exemples, montrer que la selection d'√©l√©ments des tensors se fait de la m√™me mani√®re que sur NumPy \n",
    "print(x[1][1], x[3][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Une fonctionnalit√© tr√®s utile de Pytorch, est la possibilit√© d'√©changer les tensors facilement avec NumPy.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69912364, 0.29596159],\n",
       "       [0.50143137, 0.62314591],\n",
       "       [0.16017007, 0.69218149]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er une matrice numpy avec des valeurs al√©atoires\n",
    "a = np.random.rand(3,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6991, 0.2960],\n",
       "        [0.5014, 0.6231],\n",
       "        [0.1602, 0.6922]], dtype=torch.float64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er un tensor Pytorch √† base de cette matrice np\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69912364, 0.29596159],\n",
       "       [0.50143137, 0.62314591],\n",
       "       [0.16017007, 0.69218149]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir √† nouveau ce tensor en un numpy array\n",
    "c = b.numpy()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch, comme numpy, offre une fonctionnalit√© qu'on appelle **broadcasting**. Elle permet d'ex√©cuter des op√©rations entre des tensors (resp. arrays) qui n'ont pas la m√™me forme, comme l'illustre la figure suivante:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/broadcasting.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch assouplie la contrainte de forme mais ne la supprime pas totalement. Il est primordiale d'ob√©ir les r√®gles pour effectuer des opr√©rations entre deux tensors Pytorch:\n",
    "1. Deux tensors de m√™me rang sont compatibles (broadcastable) si, pour chaque axe, soit les tailles sont √©gales, soit l‚Äôune d‚Äôelles est exactement √©gale √† 1. P.ex. (5, 3) et (1, 3) sont des formats broadcastable, (5, 3) et (5, 1) √©galement, mais (5, 3) et (3, 1) ne le sont pas.\n",
    "2. Si un tensor a un axe de taille 1, le tensor sera dupliqu√© √† la vol√©e autant de fois que n√©cessaire selon cet axe pour atteindre la taille de l‚Äôautre tensor le long de cet axe. P.ex. un tensor (2, 1, 3) pourra √™tre transform√© en tensor (2, 5, 3) en le dupliquant 5 fois le long du 2e axe (axis=1).\n",
    "3. La taille selon chaque axe apr√®s broadcast est √©gale au maximum de toutes les tailles d‚Äôentr√©e le long de cet axe. P.ex. (5, 3, 1) √ó (1, 3, 4) ‚Üí (5, 3, 4).\n",
    "4. Si un des tensors a un rang (ndim) inf√©rieur √† l‚Äôautre, alors sa forme (shape) est pr√©c√©d√©e d‚Äôautant de 1 que n√©cessaire pour atteindre le m√™me rang. P.ex. (5, 3, 1) √ó (4,) = (5, 3, 1) √ó (1, 1, 4) ‚Üí (5, 3, 4).\n",
    "\n",
    "Pour plus d'informations sur le broadcasting, vous pouvez aller sur le lien: http://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9146, 0.5507, 0.2223],\n",
      "        [0.2998, 0.7492, 0.9478],\n",
      "        [0.3621, 0.1632, 0.8242],\n",
      "        [0.8251, 0.5894, 0.7851]])\n",
      "tensor([[0.8841],\n",
      "        [0.5645],\n",
      "        [0.9412],\n",
      "        [0.3639]])\n",
      "tensor([[1.7987, 1.4348, 1.1063],\n",
      "        [0.8643, 1.3138, 1.5123],\n",
      "        [1.3033, 1.1044, 1.7655],\n",
      "        [1.1891, 0.9533, 1.1490]])\n"
     ]
    }
   ],
   "source": [
    "# Illustrer le broadcasting par un exemple\n",
    "x = torch.rand(4,3)\n",
    "y = torch.rand(4,1)\n",
    "z = x + y\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> L'unes des fonctionnalit√©s les plus pris√©e de Pytorch est qu'il permet de calculer d'une mani√®re tr√®s facile les gradients des tensors, ce qui est tr√®s utile pour appliquer les algorithmes d'optimisation par descente de gradient. Pour cela, PyTorch utilise la biblioth√®que autograd qui permet de garder une trace de l'orgine des tensors (leurs tensors parents, les op√©rations effectu√©es) et fournir automatiquement la cha√Æne des d√©riv√©es de ces op√©rations en fonction de leur input. Pytorch fournit donc le gradient d'une expression en fonction de ses param√®tres en input automatiquement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1.,  1.]], requires_grad=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er un tensor x dont la fonctionalit√© de gradient est activ√©e\n",
    "x = torch.tensor([[1., -1., 1., 1.],[1., -1., 1., 1.]] )\n",
    "x.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000, -0.5000,  0.5000,  0.5000],\n",
      "        [ 0.5000, -0.5000,  0.5000,  0.5000]], grad_fn=<MulBackward0>)\n",
      "<MulBackward0 object at 0x7f893aa5f4c0>\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un nouveau tensor y, r√©sultat d'une op√©ration lin√©aire sur le tensor x. L'attribut grad_fn trace l'op√©ration effectu√©e \n",
    "y = x * 0.5\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2500, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un tensor w qui est la moyenne de y. Vous devrez voir la diff√©rence dans grad_fn\n",
    "w = y.mean()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire un backpropagation sur votre tensor w -> ce qui revient √† automatiquement calculer dw/dx\n",
    "w.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625]])\n"
     ]
    }
   ],
   "source": [
    "# Afficher le gradient de x\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectuer une op√©ration sur x qui n'est pas trac√© dans le gradient  \n",
    "t = x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625]])\n"
     ]
    }
   ],
   "source": [
    "# Afficher le gradient de x (devrait rester le m√™me)\n",
    "print (x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch offre √©galement la possibilit√© d'effectuer les op√©rations des tensors sur CPU ou GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V√©rifier que vous avez la capacit√© d'ex√©cuter sur GPU sur votre machine\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si vous avez GPU, vous pouvez d√©placer les calculs qu'on vient de faire sur GPU\n",
    "#dommage j'ai pas du GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Vous pouvez explorer d'autres op√©rations torch peuvent √™tre explor√©es ici: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Notre premier NN\n",
    "\n",
    "![image](resources/learning.png)\n",
    "\n",
    "Source: Deep Learning with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Dans notre TP, nous allons impl√©menter un feed forward NN qui identifie les chiffres √©crits √† la main (Hello World! des NN). La difficult√© revient √† identifier le m√™me chiffre m√™me s'il est √©crit d'une mani√®re tr√®s diff√©rente. \n",
    "\n",
    "Notre NN devra prendre en input une image (28 x 28 pixels) et identifier le chiffre en output. Le Dataset utilis√©, __MNIST__, englobe 60.000 √©chantillions de chiffres √©crits √† la main par 250 personnes pour l'apprentissage, et 10.000 pour le test √©crits par un autre groupe de 250 personnes. Les √©chantillons ont √©t√© rassembl√©s et merg√©s par NIST (United States' National Institute of Standards and Technology), d'o√π le nom du dataset. \n",
    "\n",
    "Pour ce faire, nous allons cr√©er un r√©seau de neurones qui permet de **classfier** une image selon un **output label**. \n",
    "\n",
    "- Combien de Labels faudrait-il pr√©voir en output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les √©tapes pour la cr√©ation de notre NN sont les suivants:\n",
    "\n",
    "1. Lire et pr√©parer les donn√©es \n",
    "\n",
    "2. Cr√©er le r√©seau de neuronne\n",
    "\n",
    "3. Entra√Æner le r√©seau de neuronne\n",
    "\n",
    "4. Tester notre mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lire et pr√©parer les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PO-N2fynM53t"
   },
   "source": [
    "Avant d'impl√©menter tout mod√®le, il faut commencer par **Examiner et comprendre les donn√©es** puis les **formatter** convenablement pour alimenter le NN. L'objectif de cette partie est d'abord d'explorer le dataset MNIST, puis de pr√©parer les datasets input du NN.\n",
    "\n",
    "\n",
    "1.   Importer le MNIST dataset\n",
    "2.   Afficher les images avec leurs labels\n",
    "3.   Pr√©parer les donn√©es: split train, test, validation et normalisation des donn√©es\n",
    "4.   Cr√©er un Pytorch Dataset\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.   Importer le MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer la librairie torch et le module datasets de torchvision\n",
    "import torch, torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Le projet torchvision contient les meilleures architectures NN pour computer vision, ainsi que des datasets standards et utilitaires pour impl√©menter les projest computer vision. La liste des datasets du projet peut √™tre explor√©e ici: https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "Le dataset MNIST contient un sous dataset pour le training et un pour le test. R√©cup√©rer ces deux sous-dataset en deux objets dataset https://pytorch.org/docs/stable/torchvision/datasets.html#mnist\n",
    "\n",
    "N.B. Ne pas oublier de donner des noms significatifs √† vos variables.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-124-2ccd355c3374>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-124-2ccd355c3374>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    data = torchvision.datasets.MNIST(root='MNIST/processed/training.pt', train= True, transform: Optional[Callable] = None,\u001b[0m\n\u001b[0m                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# R√©cup√©rer les donn√©es d'apprentissage\n",
    "data = torchvision.datasets.MNIST(root='MNIST/processed/training.pt', train= True, transform: Optional[Callable] = None, \n",
    "                                  target_transform: Optional[Callable] = None, \n",
    "                                  download= False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les donn√©es de test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Essayons d'explorer les donn√©es dans nos datasets. MNIST devrait contenir des images de chiffres √©crits √† la main. Une image est repr√©sent√© comme un Tensor Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un datapoint de votre dataset d'apprentissage, sa forme, le type des donn√©es, les valeurs min et max. \n",
    "# Que repr√©sente les valeurs du Tensor √† votre avis?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "#### 1.2.  Afficher les images avec leurs labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utiliserons imshow de matplotlib pour afficher un √©chantillon des donn√©es. Pensez √† √©galement afficher le label correspondant √† chaque image en utilisant l'attribut targets votre objet MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un √©chantillon des images du dataset d'apprentissage avec leurs labels respectifs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "#### 1.3.  Pr√©parer les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Cr√©er un dataset de validation**\n",
    "\n",
    "Notre dataset contient les donn√©es d'apprentissage et de test, nous aurons √©galement besoin d'un dataset de validation. Pour ce faire, nous allons diviser notre dataset d'apprentissage de mani√®re √† d√©dier **10.000** data point √† la validation. \n",
    "\n",
    "Nous utiliserons la librairie scikit learn qui contient une fonction permettant de diviser les donn√©es d'une mani√®re tr√®s efficace. Pour plus de d√©tails, voir: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer la fonction de splitting des donn√©es de scikit learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er 4 tensors en r√©sultat du splitting: donn√©es d'apprentissage, donn√©es de validation, labels d'apprentissage, et labels de validation  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les labels de test √† partir de votre sous-dataset de test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Vous devez maintenant avoir 6 tensors, un pour les donn√©es et l'autre pour les labels et ce pour l'apprentissage, le test, et la validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la taille de chaque tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**Normaliser les donn√©es**\n",
    "\n",
    "Il est souvent recommand√© de normaliser les donn√©es avant d'alimenter le NN pour am√©liorer sa performance. On peut facilement redimensionner √† l'intervalle [0,1] les valeurs de nos donn√©es en utilisant la moyenne et la d√©viation standard suivant cette formule: $$(Data - Mean) / standard Deviation$$\n",
    "\n",
    "Comme \"thumb rule\", on normalise les donn√©es de test et de validation en utilisant la moyenne et la d√©viation des donn√©es d'apprentissage. Le raisonnement √©tant que les donn√©es test et validation sont indisponibles au moment de la cr√©ation du NN.   \n",
    "\n",
    "Apr√®s normalisation, le mean devrait √™tre 0 et standard deviation √† 1 (ou tr√®s proche resp. de 0 et 1).\n",
    "\n",
    "N.B. Il faudra convertir les valeurs de vos tensors en float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les valeurs des tensors en float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocker dans des variables la moyenne et la d√©viation standard des donn√©es d'apprentissage \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les donn√©es d'apprentissage, de test, et de validation par ces valeurs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la moyenne et la d√©viation standard de chaque dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "#### 1.4. Cr√©ation de Pytorch Dataset\n",
    "\n",
    "Notre Pipeline devrait commencer par le chargement des donn√©es dans le NN. Pytorch fournit un ensemble d'outils facilitant et optimisant cette t√¢che. La classe **Dataset** permet de cr√©er, sur la base de nos donn√©es, un dataset personalis√© qui pourra √™tre utilis√© par la suite par la fonction built-in **DataLoader** afin d'alimenter les donn√©es lors de l'entra√Ænement du NN. Dataset fournit un acc√®s uniforme √† nos donn√©es. DataLoader joue le r√¥le d'un data feeder en cr√©ant les batches de donn√©es qui fournissent au r√©seau de neuronne un √©chantillon de donn√©e √† chaque it√©ration.\n",
    "\n",
    "Documentation classe Dataset: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
    "\n",
    "Afin de cr√©er notre Pytorch Dataset personalis√©, nous allons h√©riter de la classe Dataset et red√©finir les fonctions suivantes:\n",
    "*   \\_\\_init__(self, data, targets): constructeur qui assignera les valeurs des attributs data et targets √† l'objet une fois instanci√©\n",
    "*   \\_\\_getitem__(self, idx) : permet de r√©cup√©rer l'item √† l'index idx. Utile pour √©viter de charger la totalit√© du Dataset en m√©moire (s'il est volumineux, on pr√©cise le chemin dans  \\_\\_init__), \n",
    "*   \\_\\_len__(self) : retroune la longeur de notre vecteur target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer Dataset de torch.utils.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une classe qui h√©rite de Dataset et red√©finit les m√©thodes comme susmentionn√©\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Nous allons instancier 3 objets (√† partir de votre classe personnalis√©e) pour les donn√©es et targets de l'apprentissage, test et validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les 3 objets en instantiant votre classe\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer DataLoader de torch.utils.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> DataLoader aide pour l'√©chantillonage et l'organisation de nos donn√©es en mini-batches. A chaque it√©ration d'apprentissage (epoch), le DataLoader fait un shuffling des donn√©es avant de les passer au NN. DataLoader prend le dataset et la taille du batch comme argument. On mettra pour l'instant une taille de 64.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une variable pour la taille du batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les objets DataLoader pour vos datasets d'apprentissage, test et validation en lui donner la taille du batch convenue\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle est la taille de vos objets dataLoader? Comment expliquer ces r√©sultats?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### 2. Cr√©er le r√©seau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch fournit le module nn qui comprend les classes repr√©sentant les briques de base pour construire un r√©seau de neurones. Il y a maintes mani√®res de cr√©er un NN sur Pytorch, nous allons explorer quelques unes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer le module nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch permet de concat√©ner des classes de notre choix pour la cr√©ation de notre NN, et ce gr√¢ce √† nn.Sequential(). Cette m√©thode prend les donn√©es en input, et se charge de faire passer les outputs interm√©diaires aux modules suivants, puis produit l'output du dernier module.\n",
    "\n",
    "Pour notre NN, nous allons cr√©er une architecture compos√©e de:\n",
    "\n",
    "1. Input Layer: Nos images ont une taille 28 x 28. On va essayer de r√©duire la taille en 64\n",
    "2. Fonction d'activation: ReLu\n",
    "3. Hidden Layer: applique une transformation lin√©aire sur les donn√©es en input, et r√©duit leur dimension en 32\n",
    "4. Fonction d'activation: ReLu\n",
    "5. Output Layer: applique une transformation lin√©aire sur les donn√©es en input, et r√©duit leur dimension en 10 (Nombre de classes)\n",
    "\n",
    "Le choix que nous venons de faire des nombres des neurones dans hidden Layer est al√©atoire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En utilisant Sequential(), cr√©er un mod√®le avec l'architecture susmentionn√©e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le nombre de param√®tres qui seront entra√Æn√©s par le NN cr√©√©. Pourquoi ce chiffre?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Sequential est une fonction standard de Pytorch. Elle n'offre pas assez de marge de personalisation. C'est pour autant qu'on a tendance √† cr√©er nos propres classe de r√©seaux de neurones, en h√©ritant de la classe nn.Module et en red√©finissant ses m√©thodes.\n",
    "\n",
    "La cr√©ation de notre Classe r√©seau de neurones se fera en h√©ritant de nn.Module et en red√©finissant:\n",
    "1. La m√©thode \\_\\_init__ o√π on initialise les couches √† utiliser (on suivra la m√™me architecture que le premier NN)\n",
    "2. La m√©thode forward o√π on sp√©cifie les connexions entre les couches. Cela permet de pr√©ciser les op√©rations qu'on appliquera sur les donn√©es √† chaque passe (et leur passage de l'input, hidden, √† l'output layer).\n",
    "\n",
    "\n",
    "Dans la fonction forward, on utilisera le module **torch.nn.Functional** qui contient un ensemble de fonctions utiles comme les fonctions d'activation... Vous pouvez voir un exemple de d√©finition d'un NN personalis√© sur la documentation de pytorch: https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer torch.nn.functional\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsXCHwP7RP0b"
   },
   "outputs": [],
   "source": [
    "# Cr√©er une classe qui h√©rite de nn.Module et red√©finir le constructeur ainsi que la m√©thode forward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier votre NN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier que vous avez le m√™me nombre de param√®tres que le premier NN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### 3. Entra√Æner le r√©seau de neuronne\n",
    "\n",
    "Maintenant que nous avons notre r√©seau de neurones, on devra commencer √† l'entra√Æner. La boucle d'apprentissage est le processus qui permettra √† notre r√©seau de neurones d'apprendre √† partir des donn√©es input et d'ajuster les poids du NN selon les r√©sultats de la fonction Loss. Pour impl√©menter notre boucle d'apprentissage sur Pytorch, nous avons besoin de:\n",
    "\n",
    "1. Pr√©ciser un nombre d'it√©ration pour l'apprentissage (epochs)\n",
    "2. D√©finir notre fonction co√ªt\n",
    "3. Choisir l'optimiseur qui permettra d'optimiser le co√ªt\n",
    "\n",
    "    \n",
    "Notre boucle d'apprentissage se fera selon le nombre des epochs d√©fini, et devra comporter: \n",
    "1. Une boucle sur les donn√©es d'entra√Ænement via DataLoader (minibatch): Alimenter les donn√©es dans le NN, Calculer le co√ªt, et faire la backpropagation. \n",
    "2. Une boucle sur les donn√©es de validation via DataLoader:  Alimenter les donn√©es dans le NN, Calculer le co√ªt, calculer un score de pr√©cision du mod√®le (on va d√©finir un score simple qui indique le nombre de pr√©visions correctes).\n",
    "\n",
    "Une bonne pratique est d'afficher les valeurs de co√ªt et de pr√©cision pour chaque epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir la fonction du co√ªt. On peut choisir CrossEntropyLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir une fonction d'optimisation des co√ªt: Adam par exemple. On devra d√©finir un learning rate. On choisira 0.001.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir le nombre d'epochs. Commencer petit. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une boucle sur les epochs:\n",
    "    \n",
    "    # Sp√©cifier qu'on est sur le mode entra√Ænement\n",
    "    \n",
    "    # initialiser notre co√ªt d'apprentissage √† 0.0\n",
    "    \n",
    "    # Boucler sur les minibatchs des donn√©es d'enta√Ænement (les donn√©es et leurs targets):\n",
    "        # le vecteur des labels pr√©dites par le mod√®le est le r√©sultat de l'application du mod√®le sur le minibatch en cours. \n",
    "        # Nous aurons besoin d'applatir les donn√©es avant de les donner √† notre NN\n",
    "        \n",
    "        # Calculer le co√ªt en comparant les labels pr√©dits aux targets du minibatch\n",
    "        \n",
    "        # Backpropagation: \n",
    "        # R√©initialiser l'optimiseur\n",
    "        # Faire la backpropagation\n",
    "        # Effectuer un pas d'optimisation\n",
    "\n",
    "        # Mettre √† jour votre co√ªt d'apprentissage en lui ajoutant le co√ªt du data batch\n",
    "    \n",
    "    # A la sortie de la boucle de l'entra√Ænement, on calcule le co√ªt moyen pour toutes les donn√©es training\n",
    "    \n",
    "    # Initiliser le co√ªt de validation √† 0.0\n",
    "    \n",
    "    # Initialiser le nombre de pr√©visions correctes √† 0\n",
    "    \n",
    "    # Sp√©cifier qu'on est sur le mode d'√©valuation\n",
    "    \n",
    "    # Indiquer √† Pytorch qu'on ne va pas faire de Gradient descent (comme on est dans l'√©valuation)\n",
    "        \n",
    "        # Boucler sur les minibatchs des donn√©es de validation (les donn√©es et leurs targets):\n",
    "            \n",
    "            # le vecteur des labels pr√©dites par le mod√®le est le r√©sultat de l'application du mod√®le sur le minibatch en cours. \n",
    "            # Nous aurons besoin d'applatir les donn√©es avant de les donner √† notre NN\n",
    "            \n",
    "            # Calculer le co√ªt en comparant les labels pr√©dits aux targets du minibatch\n",
    "            \n",
    "            # Mettre √† jour votre co√ªt de validation en lui ajoutant le co√ªt du data batch\n",
    "            \n",
    "            # Mettre √† jour le nombre de pr√©vision correctes en y ajoutant le nombre des bonnes pr√©vision sur ce batch\n",
    "            # On y compare le label pr√©dit avec le labels du minibatch. \n",
    "            # Penser √† utiliser argmax pour avoir la pr√©vision finale √† partir du vecteur de pr√©vision\n",
    "\n",
    "        # A la sortie de cette boucle, calculer le co√ªt moyen de validation\n",
    "        \n",
    "        \n",
    "        # Calculer la pr√©cision: la moyenne des pr√©visions correctes sur l'ensemble des observations dans le dataset validation \n",
    "        \n",
    "\n",
    "    # Afficher pour chaque it√©ration le co√ªt d'entra√Ænement, le co√ªt de validation, et la pr√©cision.\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### 4. Tester le mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Tester notre mod√®le revient √† calculer la pr√©cision de la m√™me mani√®re que nous avons fait tout √† l'heure, mais sur les donn√©es test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliser le co√ªt de test √† 0.0\n",
    "    \n",
    "# Initialiser le nombre de pr√©visions correctes √† 0\n",
    "    \n",
    "# Indiquer √† Pytorch qu'on ne va pas faire de Gradient descent (comme on est dans l'√©valuation)\n",
    "        \n",
    "    # Boucler sur les minibatchs des donn√©es de test (les donn√©es et leurs targets):\n",
    "            \n",
    "            # le vecteur des labels pr√©dites par le mod√®le est le r√©sultat de l'application du mod√®le sur le minibatch en cours. \n",
    "            # Nous aurons besoin d'applatir les donn√©es avant de les donner √† notre NN\n",
    "            \n",
    "            # Calculer le co√ªt en comparant les labels pr√©dits aux targets du minibatch\n",
    "            \n",
    "            # Mettre √† jour votre co√ªt de test en lui ajoutant le co√ªt du data batch\n",
    "            \n",
    "            # Mettre √† jour le nombre de pr√©vision correctes en y ajoutant le nombre des bonnes pr√©vision sur ce batch\n",
    "            # On y compare le label pr√©dit avec le labels du minibatch. \n",
    "            # Penser √† utiliser argmax pour avoir la pr√©vision finale √† partir du vecteur de pr√©vision\n",
    "\n",
    "\n",
    "        # A la sortie de cette boucle, calculer le co√ªt moyen de test\n",
    "        \n",
    "        \n",
    "        # Calculer la pr√©cision: la moyenne des pr√©visions correctes sur l'ensemble des observations dans le dataset test\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oLSMwg84dHjf"
   ],
   "name": "Coding AI - Intro to PyTorch - Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
