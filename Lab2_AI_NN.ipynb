{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travaux Pratiques Intelligence Artificielle: Lab2\n",
    "\n",
    "Neural Networks avec Pytorch ü§ñ üôå.\n",
    "\n",
    "## Objectifs du TP:\n",
    "\n",
    "> **Se Familiariser avec Pytorch** \n",
    "\n",
    "> **Comprendre le processus d'apprentissage d'un r√©seau de neurones**\n",
    "\n",
    "> **Cr√©er un r√©seau de neurones (feed-forward multilayers NN) avec Pytorch**\n",
    "\n",
    "\n",
    "\n",
    "<br></br>\n",
    "_Besoin d'aide? Laisser moi un Commentaire sur Teams_\n",
    "\n",
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Introduction √† Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch est une librairie open source Python, developp√©e par AI Research lab (FAIR) de Facebook et publi√©e en ligne en Sept. 2016. Elle permet d'effectuer les calculs tensoriels n√©cessaires notamment pour l'apprentissage profond (deep learning).   \n",
    "\n",
    "Pytorch permet une impl√©mentation et un apprentissage facile des r√©seaux de neurones (NN). Elle est tr√®s proche de la syntaxe de Python, d'ailleurs il est m√™me possible d'int√©grer des blocs if else dans un code NN. Elle a une riche communaut√© et une documentation actualis√©e (compar√©e √† tensorflow). D'autant plus qu'elle est tr√®s utilis√©e par les chercheurs, ce qui garantie l'impl√©mentation des nouveaux mod√®les sur Pytorch.\n",
    "\n",
    "Vous pouvez installer Pytorch √† partir d'un terminal ou au niveau de ce jupyter en ex√©cutant la cellule ci-dessous. \n",
    "\n",
    "**N.B.** Si vous avez des inconsistences au niveau de l'installation, pensez √† cr√©er un environnement sp√©cifique pour ce TP.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Afin de mener √† bien les impl√©mentations des NN, Pytorch fournit l'objet **Tensor**. Un tensor sur Pytorch a les m√™mes fonctions et syntaxe qu'un numpy array mais est optimis√© pour GPU. D'autant plus que son backend C++ permet √† Pytorch d'√™tre beaucoup plus performante et rapide que numpy. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "# Importer torch\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# cr√©er une matrice identit√© de taille 4x4\n",
    "eye4 = torch.eye(4)\n",
    "print(eye4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6426, 0.5716, 0.3965],\n",
      "        [0.9133, 0.8844, 0.7925],\n",
      "        [0.6661, 0.8868, 0.0243],\n",
      "        [0.2956, 0.6687, 0.5823]])\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un tensor avec des valeurs al√©atoires d'une taille de votre choix\n",
    "x = torch.rand(4,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6426, 0.5716, 0.3965, 0.9133],\n",
       "        [0.8844, 0.7925, 0.6661, 0.8868],\n",
       "        [0.0243, 0.2956, 0.6687, 0.5823]])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changer la forme de votre tensor \n",
    "x.view(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher la taille, la forme,\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# et le type des √©l√©ments de votre tensor\n",
    "x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = x.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.6426, 20.5716, 20.3965],\n",
       "        [20.9133, 20.8844, 20.7925],\n",
       "        [20.6661, 20.8868, 20.0243],\n",
       "        [20.2956, 20.6687, 20.5823]])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajouter une constante fixe √† l'ensemble des √©l√©ments du tensor\n",
    "torch.add(x, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8969, 1.4066, 0.9446, 0.8031],\n",
       "        [1.4066, 2.2444, 1.4119, 1.3229],\n",
       "        [0.9446, 1.4119, 1.2307, 0.8041],\n",
       "        [0.8031, 1.3229, 0.8041, 0.8736]])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplier votre tensor par sa transpos√© (multiplication matricielle, pas element-wise)\n",
    "torch.mm(x,xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8844) tensor(0.5823)\n"
     ]
    }
   ],
   "source": [
    "# Avec quelques exemples, montrer que la selection d'√©l√©ments des tensors se fait de la m√™me mani√®re que sur NumPy \n",
    "print(x[1][1], x[3][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Une fonctionnalit√© tr√®s utile de Pytorch, est la possibilit√© d'√©changer les tensors facilement avec NumPy.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22566503, 0.0077546 ],\n",
       "       [0.47035519, 0.43104928],\n",
       "       [0.7979381 , 0.4146357 ]])"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er une matrice numpy avec des valeurs al√©atoires\n",
    "a = np.random.rand(3,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2257, 0.0078],\n",
       "        [0.4704, 0.4310],\n",
       "        [0.7979, 0.4146]], dtype=torch.float64)"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er un tensor Pytorch √† base de cette matrice np\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22566503, 0.0077546 ],\n",
       "       [0.47035519, 0.43104928],\n",
       "       [0.7979381 , 0.4146357 ]])"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir √† nouveau ce tensor en un numpy array\n",
    "c = b.numpy()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch, comme numpy, offre une fonctionnalit√© qu'on appelle **broadcasting**. Elle permet d'ex√©cuter des op√©rations entre des tensors (resp. arrays) qui n'ont pas la m√™me forme, comme l'illustre la figure suivante:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/broadcasting.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch assouplie la contrainte de forme mais ne la supprime pas totalement. Il est primordiale d'ob√©ir les r√®gles pour effectuer des opr√©rations entre deux tensors Pytorch:\n",
    "1. Deux tensors de m√™me rang sont compatibles (broadcastable) si, pour chaque axe, soit les tailles sont √©gales, soit l‚Äôune d‚Äôelles est exactement √©gale √† 1. P.ex. (5, 3) et (1, 3) sont des formats broadcastable, (5, 3) et (5, 1) √©galement, mais (5, 3) et (3, 1) ne le sont pas.\n",
    "2. Si un tensor a un axe de taille 1, le tensor sera dupliqu√© √† la vol√©e autant de fois que n√©cessaire selon cet axe pour atteindre la taille de l‚Äôautre tensor le long de cet axe. P.ex. un tensor (2, 1, 3) pourra √™tre transform√© en tensor (2, 5, 3) en le dupliquant 5 fois le long du 2e axe (axis=1).\n",
    "3. La taille selon chaque axe apr√®s broadcast est √©gale au maximum de toutes les tailles d‚Äôentr√©e le long de cet axe. P.ex. (5, 3, 1) √ó (1, 3, 4) ‚Üí (5, 3, 4).\n",
    "4. Si un des tensors a un rang (ndim) inf√©rieur √† l‚Äôautre, alors sa forme (shape) est pr√©c√©d√©e d‚Äôautant de 1 que n√©cessaire pour atteindre le m√™me rang. P.ex. (5, 3, 1) √ó (4,) = (5, 3, 1) √ó (1, 1, 4) ‚Üí (5, 3, 4).\n",
    "\n",
    "Pour plus d'informations sur le broadcasting, vous pouvez aller sur le lien: http://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8108, 0.7675, 0.0966],\n",
      "        [0.2814, 0.9338, 0.5881],\n",
      "        [0.7884, 0.1962, 0.0430],\n",
      "        [0.1867, 0.1275, 0.3935]])\n",
      "tensor([[0.6495],\n",
      "        [0.1556],\n",
      "        [0.4109],\n",
      "        [0.3547]])\n",
      "tensor([[1.4603, 1.4170, 0.7461],\n",
      "        [0.4370, 1.0894, 0.7437],\n",
      "        [1.1992, 0.6070, 0.4538],\n",
      "        [0.5413, 0.4821, 0.7482]])\n"
     ]
    }
   ],
   "source": [
    "# Illustrer le broadcasting par un exemple\n",
    "x = torch.rand(4,3)\n",
    "y = torch.rand(4,1)\n",
    "z = x + y\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> L'unes des fonctionnalit√©s les plus pris√©e de Pytorch est qu'il permet de calculer d'une mani√®re tr√®s facile les gradients des tensors, ce qui est tr√®s utile pour appliquer les algorithmes d'optimisation par descente de gradient. Pour cela, PyTorch utilise la biblioth√®que autograd qui permet de garder une trace de l'orgine des tensors (leurs tensors parents, les op√©rations effectu√©es) et fournir automatiquement la cha√Æne des d√©riv√©es de ces op√©rations en fonction de leur input. Pytorch fournit donc le gradient d'une expression en fonction de ses param√®tres en input automatiquement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1.,  1.]], requires_grad=True)"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er un tensor x dont la fonctionalit√© de gradient est activ√©e\n",
    "x = torch.tensor([[1., -1., 1., 1.],[1., -1., 1., 1.]] )\n",
    "x.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000, -0.5000,  0.5000,  0.5000],\n",
      "        [ 0.5000, -0.5000,  0.5000,  0.5000]], grad_fn=<MulBackward0>)\n",
      "<MulBackward0 object at 0x7f891a260ca0>\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un nouveau tensor y, r√©sultat d'une op√©ration lin√©aire sur le tensor x. L'attribut grad_fn trace l'op√©ration effectu√©e \n",
    "y = x * 0.5\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2500, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un tensor w qui est la moyenne de y. Vous devrez voir la diff√©rence dans grad_fn\n",
    "w = y.mean()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire un backpropagation sur votre tensor w -> ce qui revient √† automatiquement calculer dw/dx\n",
    "w.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625]])\n"
     ]
    }
   ],
   "source": [
    "# Afficher le gradient de x\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2., -2.,  2.,  2.],\n",
      "        [ 2., -2.,  2.,  2.]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Effectuer une op√©ration sur x qui n'est pas trac√© dans le gradient  \n",
    "with torch.no_grad():\n",
    "    z = x * 2\n",
    "    print(z)\n",
    "    print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625]])\n"
     ]
    }
   ],
   "source": [
    "# Afficher le gradient de x (devrait rester le m√™me)\n",
    "print (x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch offre √©galement la possibilit√© d'effectuer les op√©rations des tensors sur CPU ou GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V√©rifier que vous avez la capacit√© d'ex√©cuter sur GPU sur votre machine\n",
    "dev = torch.device(\"gpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si vous avez GPU, vous pouvez d√©placer les calculs qu'on vient de faire sur GPU\n",
    "#dommage j'ai pas du GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Vous pouvez explorer d'autres op√©rations torch peuvent √™tre explor√©es ici: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Notre premier NN\n",
    "\n",
    "![image](resources/learning.png)\n",
    "\n",
    "Source: Deep Learning with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Dans notre TP, nous allons impl√©menter un feed forward NN qui identifie les chiffres √©crits √† la main (Hello World! des NN). La difficult√© revient √† identifier le m√™me chiffre m√™me s'il est √©crit d'une mani√®re tr√®s diff√©rente. \n",
    "\n",
    "Notre NN devra prendre en input une image (28 x 28 pixels) et identifier le chiffre en output. Le Dataset utilis√©, __MNIST__, englobe 60.000 √©chantillions de chiffres √©crits √† la main par 250 personnes pour l'apprentissage, et 10.000 pour le test √©crits par un autre groupe de 250 personnes. Les √©chantillons ont √©t√© rassembl√©s et merg√©s par NIST (United States' National Institute of Standards and Technology), d'o√π le nom du dataset. \n",
    "\n",
    "Pour ce faire, nous allons cr√©er un r√©seau de neurones qui permet de **classfier** une image selon un **output label**. \n",
    "\n",
    "- Combien de Labels faudrait-il pr√©voir en output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 (output)\n",
    "28*28 (input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les √©tapes pour la cr√©ation de notre NN sont les suivants:\n",
    "\n",
    "1. Lire et pr√©parer les donn√©es \n",
    "\n",
    "2. Cr√©er le r√©seau de neuronne\n",
    "\n",
    "3. Entra√Æner le r√©seau de neuronne\n",
    "\n",
    "4. Tester notre mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lire et pr√©parer les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PO-N2fynM53t"
   },
   "source": [
    "Avant d'impl√©menter tout mod√®le, il faut commencer par **Examiner et comprendre les donn√©es** puis les **formatter** convenablement pour alimenter le NN. L'objectif de cette partie est d'abord d'explorer le dataset MNIST, puis de pr√©parer les datasets input du NN.\n",
    "\n",
    "\n",
    "1.   Importer le MNIST dataset\n",
    "2.   Afficher les images avec leurs labels\n",
    "3.   Pr√©parer les donn√©es: split train, test, validation et normalisation des donn√©es\n",
    "4.   Cr√©er un Pytorch Dataset\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.   Importer le MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer la librairie torch et le module datasets de torchvision\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Le projet torchvision contient les meilleures architectures NN pour computer vision, ainsi que des datasets standards et utilitaires pour impl√©menter les projest computer vision. La liste des datasets du projet peut √™tre explor√©e ici: https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "Le dataset MNIST contient un sous dataset pour le training et un pour le test. R√©cup√©rer ces deux sous-dataset en deux objets dataset https://pytorch.org/docs/stable/torchvision/datasets.html#mnist\n",
    "\n",
    "N.B. Ne pas oublier de donner des noms significatifs √† vos variables.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les donn√©es d'apprentissage\n",
    "downloaded_train = datasets.MNIST(root='./resources', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les donn√©es de test\n",
    "downloaded_test = datasets.MNIST(root='./resources', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Essayons d'explorer les donn√©es dans nos datasets. MNIST devrait contenir des images de chiffres √©crits √† la main. Une image est repr√©sent√© comme un Tensor Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./resources\n",
      "    Split: Train\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./resources\n",
      "    Split: Test\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Afficher un datapoint de votre dataset d'apprentissage, sa forme, le type des donn√©es, les valeurs min et max. \n",
    "# Que repr√©sente les valeurs du Tensor √† votre avis?\n",
    "print(downloaded_train)\n",
    "print(downloaded_test)\n",
    "print(downloaded_train.data[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(downloaded_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(255, dtype=torch.uint8)"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(data_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CenterCrop',\n",
       " 'ColorJitter',\n",
       " 'Compose',\n",
       " 'ConvertImageDtype',\n",
       " 'FiveCrop',\n",
       " 'GaussianBlur',\n",
       " 'Grayscale',\n",
       " 'Lambda',\n",
       " 'LinearTransformation',\n",
       " 'Normalize',\n",
       " 'PILToTensor',\n",
       " 'Pad',\n",
       " 'RandomAffine',\n",
       " 'RandomApply',\n",
       " 'RandomChoice',\n",
       " 'RandomCrop',\n",
       " 'RandomErasing',\n",
       " 'RandomGrayscale',\n",
       " 'RandomHorizontalFlip',\n",
       " 'RandomOrder',\n",
       " 'RandomPerspective',\n",
       " 'RandomResizedCrop',\n",
       " 'RandomRotation',\n",
       " 'RandomSizedCrop',\n",
       " 'RandomVerticalFlip',\n",
       " 'Resize',\n",
       " 'Scale',\n",
       " 'TenCrop',\n",
       " 'ToPILImage',\n",
       " 'ToTensor',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'functional',\n",
       " 'functional_pil',\n",
       " 'functional_tensor',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "#### 1.2.  Afficher les images avec leurs labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utiliserons imshow de matplotlib pour afficher un √©chantillon des donn√©es. Pensez √† √©galement afficher le label correspondant √† chaque image en utilisant l'attribut targets votre objet MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '9')"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Afficher un √©chantillon des images du dataset d'apprentissage avec leurs labels respectifs \n",
    "\n",
    "plt.imshow(downloaded_train.data[4], cmap=\"gray\")\n",
    "plt.title(downloaded_train.targets[4].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "#### 1.3.  Pr√©parer les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Cr√©er un dataset de validation**\n",
    "\n",
    "Notre dataset contient les donn√©es d'apprentissage et de test, nous aurons √©galement besoin d'un dataset de validation. Pour ce faire, nous allons diviser notre dataset d'apprentissage de mani√®re √† d√©dier **10.000** data point √† la validation. \n",
    "\n",
    "Nous utiliserons la librairie scikit learn qui contient une fonction permettant de diviser les donn√©es d'une mani√®re tr√®s efficace. Pour plus de d√©tails, voir: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer la fonction de splitting des donn√©es de scikit learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er 4 tensors en r√©sultat du splitting: donn√©es d'apprentissage, donn√©es de validation, labels d'apprentissage, et labels de validation  \n",
    "train_data, validation_data, train_targets, validation_targets = train_test_split(downloaded_train.data, downloaded_train.targets, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les labels de test √† partir de votre sous-dataset de test\n",
    "test_data = downloaded_test.data\n",
    "test_targets = downloaded_test.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Vous devez maintenant avoir 6 tensors, un pour les donn√©es et l'autre pour les labels et ce pour l'apprentissage, le test, et la validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 28, 28]) torch.Size([50000])\n",
      "torch.Size([10000, 28, 28]) torch.Size([10000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# Afficher la taille de chaque tensor\n",
    "print(train_data.shape, train_targets.shape)\n",
    "print(validation_data.shape, validation_targets.shape)\n",
    "print(test_targets.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**Normaliser les donn√©es**\n",
    "\n",
    "Il est souvent recommand√© de normaliser les donn√©es avant d'alimenter le NN pour am√©liorer sa performance. On peut facilement redimensionner √† l'intervalle [0,1] les valeurs de nos donn√©es en utilisant la moyenne et la d√©viation standard suivant cette formule: $$(Data - Mean) / standard Deviation$$\n",
    "\n",
    "Comme \"thumb rule\", on normalise les donn√©es de test et de validation en utilisant la moyenne et la d√©viation des donn√©es d'apprentissage. Le raisonnement √©tant que les donn√©es test et validation sont indisponibles au moment de la cr√©ation du NN.   \n",
    "\n",
    "Apr√®s normalisation, le mean devrait √™tre 0 et standard deviation √† 1 (ou tr√®s proche resp. de 0 et 1).\n",
    "\n",
    "N.B. Il faudra convertir les valeurs de vos tensors en float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les valeurs des tensors en float\n",
    "train_data = train_data.float()\n",
    "test_data = test_data.float()\n",
    "validation_data = validation_data.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocker dans des variables la moyenne et la d√©viation standard des donn√©es d'apprentissage \n",
    "mean_train = torch.mean(train_data)\n",
    "std_train = torch.std(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les donn√©es d'apprentissage, de test, et de validation par ces valeurs\n",
    "train_data = (train_data - mean_train)/std_train\n",
    "test_data = (test_data - mean_train)/std_train\n",
    "validation_data = (validation_data - mean_train)/std_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.2693e-09) tensor(1.0000)\n",
      "tensor(0.0065) tensor(1.0083)\n",
      "tensor(0.0029) tensor(1.0033)\n"
     ]
    }
   ],
   "source": [
    "# Afficher la moyenne et la d√©viation standard de chaque dataset\n",
    "print(train_data.mean(), train_data.std())\n",
    "print(test_data.mean(),test_data.std())\n",
    "print(validation_data.mean(), validation_data.std())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "#### 1.4. Cr√©ation de Pytorch Dataset\n",
    "\n",
    "Notre Pipeline devrait commencer par le chargement des donn√©es dans le NN. Pytorch fournit un ensemble d'outils facilitant et optimisant cette t√¢che. La classe **Dataset** permet de cr√©er, sur la base de nos donn√©es, un dataset personalis√© qui pourra √™tre utilis√© par la suite par la fonction built-in **DataLoader** afin d'alimenter les donn√©es lors de l'entra√Ænement du NN. Dataset fournit un acc√®s uniforme √† nos donn√©es. DataLoader joue le r√¥le d'un data feeder en cr√©ant les batches de donn√©es qui fournissent au r√©seau de neuronne un √©chantillon de donn√©e √† chaque it√©ration.\n",
    "\n",
    "Documentation classe Dataset: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
    "\n",
    "Afin de cr√©er notre Pytorch Dataset personalis√©, nous allons h√©riter de la classe Dataset et red√©finir les fonctions suivantes:\n",
    "*   \\_\\_init__(self, data, targets): constructeur qui assignera les valeurs des attributs data et targets √† l'objet une fois instanci√©\n",
    "*   \\_\\_getitem__(self, idx) : permet de r√©cup√©rer l'item √† l'index idx. Utile pour √©viter de charger la totalit√© du Dataset en m√©moire (s'il est volumineux, on pr√©cise le chemin dans  \\_\\_init__), \n",
    "*   \\_\\_len__(self) : retroune la longeur de notre vecteur target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer Dataset de torch.utils.data\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une classe qui h√©rite de Dataset et red√©finit les m√©thodes comme susmentionn√©\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super(MyDataset, self)\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Nous allons instancier 3 objets (√† partir de votre classe personnalis√©e) pour les donn√©es et targets de l'apprentissage, test et validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les 3 objets en instantiant votre classe\n",
    "train_dataset = MyDataset(train_data, train_targets)\n",
    "test_dataset = MyDataset(test_data, test_targets)\n",
    "validation_dataset = MyDataset(validation_data, validation_targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer DataLoader de torch.utils.data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> DataLoader aide pour l'√©chantillonage et l'organisation de nos donn√©es en mini-batches. A chaque it√©ration d'apprentissage (epoch), le DataLoader fait un shuffling des donn√©es avant de les passer au NN. DataLoader prend le dataset et la taille du batch comme argument. On mettra pour l'instant une taille de 64.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une variable pour la taille du batch\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les objets DataLoader pour vos datasets d'apprentissage, test et validation en lui donner la taille du batch convenue\n",
    "\n",
    "train_DL = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_DL = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_DL = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quelle est la taille de vos objets dataLoader? Comment expliquer ces r√©sultats?\n",
    "len(train_DL) #50000/64 nbres des batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### 2. Cr√©er le r√©seau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch fournit le module nn qui comprend les classes repr√©sentant les briques de base pour construire un r√©seau de neurones. Il y a maintes mani√®res de cr√©er un NN sur Pytorch, nous allons explorer quelques unes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer le module nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch permet de concat√©ner des classes de notre choix pour la cr√©ation de notre NN, et ce gr√¢ce √† nn.Sequential(). Cette m√©thode prend les donn√©es en input, et se charge de faire passer les outputs interm√©diaires aux modules suivants, puis produit l'output du dernier module.\n",
    "\n",
    "Pour notre NN, nous allons cr√©er une architecture compos√©e de:\n",
    "\n",
    "1. Input Layer: Nos images ont une taille 28 x 28. On va essayer de r√©duire la taille en 64\n",
    "2. Fonction d'activation: ReLu\n",
    "3. Hidden Layer: applique une transformation lin√©aire sur les donn√©es en input, et r√©duit leur dimension en 32\n",
    "4. Fonction d'activation: ReLu\n",
    "5. Output Layer: applique une transformation lin√©aire sur les donn√©es en input, et r√©duit leur dimension en 10 (Nombre de classes)\n",
    "\n",
    "Le choix que nous venons de faire des nombres des neurones dans hidden Layer est al√©atoire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En utilisant Sequential(), cr√©er un mod√®le avec l'architecture susmentionn√©e\n",
    "layers = []\n",
    "layers.append(nn.Linear(784, 64))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(64, 32))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(32, 10))\n",
    "\n",
    "net = nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52650"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher le nombre de param√®tres qui seront entra√Æn√©s par le NN cr√©√©. Pourquoi ce chiffre?\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Sequential est une fonction standard de Pytorch. Elle n'offre pas assez de marge de personalisation. C'est pour autant qu'on a tendance √† cr√©er nos propres classe de r√©seaux de neurones, en h√©ritant de la classe nn.Module et en red√©finissant ses m√©thodes.\n",
    "\n",
    "La cr√©ation de notre Classe r√©seau de neurones se fera en h√©ritant de nn.Module et en red√©finissant:\n",
    "1. La m√©thode \\_\\_init__ o√π on initialise les couches √† utiliser (on suivra la m√™me architecture que le premier NN)\n",
    "2. La m√©thode forward o√π on sp√©cifie les connexions entre les couches. Cela permet de pr√©ciser les op√©rations qu'on appliquera sur les donn√©es √† chaque passe (et leur passage de l'input, hidden, √† l'output layer).\n",
    "\n",
    "\n",
    "Dans la fonction forward, on utilisera le module **torch.nn.Functional** qui contient un ensemble de fonctions utiles comme les fonctions d'activation... Vous pouvez voir un exemple de d√©finition d'un NN personalis√© sur la documentation de pytorch: https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer torch.nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsXCHwP7RP0b"
   },
   "outputs": [],
   "source": [
    "# Cr√©er une classe qui h√©rite de nn.Module et red√©finir le constructeur ainsi que la m√©thode forward\n",
    "class Net (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier votre NN\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52650"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V√©rifier que vous avez le m√™me nombre de param√®tres que le premier NN\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "pytorch_total_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### 3. Entra√Æner le r√©seau de neuronne\n",
    "\n",
    "Maintenant que nous avons notre r√©seau de neurones, on devra commencer √† l'entra√Æner. La boucle d'apprentissage est le processus qui permettra √† notre r√©seau de neurones d'apprendre √† partir des donn√©es input et d'ajuster les poids du NN selon les r√©sultats de la fonction Loss. Pour impl√©menter notre boucle d'apprentissage sur Pytorch, nous avons besoin de:\n",
    "\n",
    "1. Pr√©ciser un nombre d'it√©ration pour l'apprentissage (epochs)\n",
    "2. D√©finir notre fonction co√ªt\n",
    "3. Choisir l'optimiseur qui permettra d'optimiser le co√ªt\n",
    "\n",
    "    \n",
    "Notre boucle d'apprentissage se fera selon le nombre des epochs d√©fini, et devra comporter: \n",
    "1. Une boucle sur les donn√©es d'entra√Ænement via DataLoader (minibatch): Alimenter les donn√©es dans le NN, Calculer le co√ªt, et faire la backpropagation. \n",
    "2. Une boucle sur les donn√©es de validation via DataLoader:  Alimenter les donn√©es dans le NN, Calculer le co√ªt, calculer un score de pr√©cision du mod√®le (on va d√©finir un score simple qui indique le nombre de pr√©visions correctes).\n",
    "\n",
    "Une bonne pratique est d'afficher les valeurs de co√ªt et de pr√©cision pour chaque epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir la fonction du co√ªt. On peut choisir CrossEntropyLoss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir une fonction d'optimisation des co√ªt: Adam par exemple. On devra d√©finir un learning rate. On choisira 0.001.\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir le nombre d'epochs. Commencer petit. \n",
    "ep = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0176, grad_fn=<NllLossBackward>)\n",
      "Accuracy:  0.961\n"
     ]
    }
   ],
   "source": [
    "# boucle d'apprentissage:\n",
    "for epoch in range(ep):\n",
    "    for data in train_DL:\n",
    "        feature, label = data\n",
    "        net.zero_grad()\n",
    "        output = net(feature.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(loss)\n",
    "\n",
    "# boucle de validation:\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validation_DL:\n",
    "        feature, label = data\n",
    "        output = net(feature.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == label[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### 4. Tester le mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Tester notre mod√®le revient √† calculer la pr√©cision de la m√™me mani√®re que nous avons fait tout √† l'heure, mais sur les donn√©es test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.961\n"
     ]
    }
   ],
   "source": [
    "# boucle de test:\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validation_DL:\n",
    "        feature, label = data\n",
    "        output = net(feature.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == label[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(feature[0].view(28,28))\n",
    "plt.title(torch.argmax(net(feature[0].view(-1, 28*28))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BY BENDER & BENHIMA"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oLSMwg84dHjf"
   ],
   "name": "Coding AI - Intro to PyTorch - Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
