{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travaux Pratiques Intelligence Artificielle: Lab2\n",
    "\n",
    "Neural Networks avec Pytorch ü§ñ üôå.\n",
    "\n",
    "## Objectifs du TP:\n",
    "\n",
    "> **Se Familiariser avec Pytorch** \n",
    "\n",
    "> **Comprendre le processus d'apprentissage d'un r√©seau de neurones**\n",
    "\n",
    "> **Cr√©er un r√©seau de neurones (feed-forward multilayers NN) avec Pytorch**\n",
    "\n",
    "\n",
    "\n",
    "<br></br>\n",
    "_Besoin d'aide? Laisser moi un Commentaire sur Teams_\n",
    "\n",
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Introduction √† Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch est une librairie open source Python, developp√©e par AI Research lab (FAIR) de Facebook et publi√©e en ligne en Sept. 2016. Elle permet d'effectuer les calculs tensoriels n√©cessaires notamment pour l'apprentissage profond (deep learning).   \n",
    "\n",
    "Pytorch permet une impl√©mentation et un apprentissage facile des r√©seaux de neurones (NN). Elle est tr√®s proche de la syntaxe de Python, d'ailleurs il est m√™me possible d'int√©grer des blocs if else dans un code NN. Elle a une riche communaut√© et une documentation actualis√©e (compar√©e √† tensorflow). D'autant plus qu'elle est tr√®s utilis√©e par les chercheurs, ce qui garantie l'impl√©mentation des nouveaux mod√®les sur Pytorch.\n",
    "\n",
    "Vous pouvez installer Pytorch √† partir d'un terminal ou au niveau de ce jupyter en ex√©cutant la cellule ci-dessous. \n",
    "\n",
    "**N.B.** Si vous avez des inconsistences au niveau de l'installation, pensez √† cr√©er un environnement sp√©cifique pour ce TP.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Afin de mener √† bien les impl√©mentations des NN, Pytorch fournit l'objet **Tensor**. Un tensor sur Pytorch a les m√™mes fonctions et syntaxe qu'un numpy array mais est optimis√© pour GPU. D'autant plus que son backend C++ permet √† Pytorch d'√™tre beaucoup plus performante et rapide que numpy. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "# Importer torch\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# cr√©er une matrice identit√© de taille 4x4\n",
    "eye4 = torch.eye(4)\n",
    "print(eye4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4549, 0.7717, 0.5609],\n",
      "        [0.9168, 0.8196, 0.0202],\n",
      "        [0.9549, 0.7612, 0.5930],\n",
      "        [0.1226, 0.3211, 0.9093]])\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un tensor avec des valeurs al√©atoires d'une taille de votre choix\n",
    "x = torch.rand(4,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4549, 0.7717, 0.5609, 0.9168],\n",
       "        [0.8196, 0.0202, 0.9549, 0.7612],\n",
       "        [0.5930, 0.1226, 0.3211, 0.9093]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changer la forme de votre tensor \n",
    "x.view(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher la taille, la forme,\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# et le type des √©l√©ments de votre tensor\n",
    "x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = x.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.4549, 20.7717, 20.5609],\n",
       "        [20.9168, 20.8196, 20.0202],\n",
       "        [20.9549, 20.7612, 20.5931],\n",
       "        [20.1226, 20.3211, 20.9093]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajouter une constante fixe √† l'ensemble des √©l√©ments du tensor\n",
    "torch.add(x, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1171, 1.0609, 1.3545, 0.8136],\n",
       "        [1.0609, 1.5126, 1.5113, 0.3939],\n",
       "        [1.3545, 1.5113, 1.8430, 0.9008],\n",
       "        [0.8136, 0.3939, 0.9008, 0.9450]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplier votre tensor par sa transpos√© (multiplication matricielle, pas element-wise)\n",
    "torch.mm(x,xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8196) tensor(0.9093)\n"
     ]
    }
   ],
   "source": [
    "# Avec quelques exemples, montrer que la selection d'√©l√©ments des tensors se fait de la m√™me mani√®re que sur NumPy \n",
    "print(x[1][1], x[3][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Une fonctionnalit√© tr√®s utile de Pytorch, est la possibilit√© d'√©changer les tensors facilement avec NumPy.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03822827, 0.59591694],\n",
       "       [0.97597175, 0.86107917],\n",
       "       [0.90095087, 0.59798742]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er une matrice numpy avec des valeurs al√©atoires\n",
    "a = np.random.rand(3,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0382, 0.5959],\n",
       "        [0.9760, 0.8611],\n",
       "        [0.9010, 0.5980]], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er un tensor Pytorch √† base de cette matrice np\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03822827, 0.59591694],\n",
       "       [0.97597175, 0.86107917],\n",
       "       [0.90095087, 0.59798742]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir √† nouveau ce tensor en un numpy array\n",
    "c = b.numpy()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch, comme numpy, offre une fonctionnalit√© qu'on appelle **broadcasting**. Elle permet d'ex√©cuter des op√©rations entre des tensors (resp. arrays) qui n'ont pas la m√™me forme, comme l'illustre la figure suivante:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/broadcasting.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch assouplie la contrainte de forme mais ne la supprime pas totalement. Il est primordiale d'ob√©ir les r√®gles pour effectuer des opr√©rations entre deux tensors Pytorch:\n",
    "1. Deux tensors de m√™me rang sont compatibles (broadcastable) si, pour chaque axe, soit les tailles sont √©gales, soit l‚Äôune d‚Äôelles est exactement √©gale √† 1. P.ex. (5, 3) et (1, 3) sont des formats broadcastable, (5, 3) et (5, 1) √©galement, mais (5, 3) et (3, 1) ne le sont pas.\n",
    "2. Si un tensor a un axe de taille 1, le tensor sera dupliqu√© √† la vol√©e autant de fois que n√©cessaire selon cet axe pour atteindre la taille de l‚Äôautre tensor le long de cet axe. P.ex. un tensor (2, 1, 3) pourra √™tre transform√© en tensor (2, 5, 3) en le dupliquant 5 fois le long du 2e axe (axis=1).\n",
    "3. La taille selon chaque axe apr√®s broadcast est √©gale au maximum de toutes les tailles d‚Äôentr√©e le long de cet axe. P.ex. (5, 3, 1) √ó (1, 3, 4) ‚Üí (5, 3, 4).\n",
    "4. Si un des tensors a un rang (ndim) inf√©rieur √† l‚Äôautre, alors sa forme (shape) est pr√©c√©d√©e d‚Äôautant de 1 que n√©cessaire pour atteindre le m√™me rang. P.ex. (5, 3, 1) √ó (4,) = (5, 3, 1) √ó (1, 1, 4) ‚Üí (5, 3, 4).\n",
    "\n",
    "Pour plus d'informations sur le broadcasting, vous pouvez aller sur le lien: http://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3738, 0.8390, 0.1726],\n",
      "        [0.0157, 0.5283, 0.8665],\n",
      "        [0.4588, 0.1444, 0.2492],\n",
      "        [0.2644, 0.8115, 0.7549]])\n",
      "tensor([[0.9944],\n",
      "        [0.4169],\n",
      "        [0.4131],\n",
      "        [0.7936]])\n",
      "tensor([[1.3682, 1.8334, 1.1670],\n",
      "        [0.4326, 0.9452, 1.2833],\n",
      "        [0.8719, 0.5575, 0.6623],\n",
      "        [1.0580, 1.6051, 1.5485]])\n"
     ]
    }
   ],
   "source": [
    "# Illustrer le broadcasting par un exemple\n",
    "x = torch.rand(4,3)\n",
    "y = torch.rand(4,1)\n",
    "z = x + y\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> L'unes des fonctionnalit√©s les plus pris√©e de Pytorch est qu'il permet de calculer d'une mani√®re tr√®s facile les gradients des tensors, ce qui est tr√®s utile pour appliquer les algorithmes d'optimisation par descente de gradient. Pour cela, PyTorch utilise la biblioth√®que autograd qui permet de garder une trace de l'orgine des tensors (leurs tensors parents, les op√©rations effectu√©es) et fournir automatiquement la cha√Æne des d√©riv√©es de ces op√©rations en fonction de leur input. Pytorch fournit donc le gradient d'une expression en fonction de ses param√®tres en input automatiquement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1.,  1.]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cr√©er un tensor x dont la fonctionalit√© de gradient est activ√©e\n",
    "x = torch.tensor([[1., -1., 1., 1.],[1., -1., 1., 1.]] )\n",
    "x.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000, -0.5000,  0.5000,  0.5000],\n",
      "        [ 0.5000, -0.5000,  0.5000,  0.5000]], grad_fn=<MulBackward0>)\n",
      "<MulBackward0 object at 0x7fb83861bf40>\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un nouveau tensor y, r√©sultat d'une op√©ration lin√©aire sur le tensor x. L'attribut grad_fn trace l'op√©ration effectu√©e \n",
    "y = x * 0.5\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2500, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un tensor w qui est la moyenne de y. Vous devrez voir la diff√©rence dans grad_fn\n",
    "w = y.mean()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire un backpropagation sur votre tensor w -> ce qui revient √† automatiquement calculer dw/dx\n",
    "w.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625]])\n"
     ]
    }
   ],
   "source": [
    "# Afficher le gradient de x\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2., -2.,  2.,  2.],\n",
      "        [ 2., -2.,  2.,  2.]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Effectuer une op√©ration sur x qui n'est pas trac√© dans le gradient  \n",
    "with torch.no_grad():\n",
    "    z = x * 2\n",
    "    print(z)\n",
    "    print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0625, 0.0625, 0.0625, 0.0625],\n",
      "        [0.0625, 0.0625, 0.0625, 0.0625]])\n"
     ]
    }
   ],
   "source": [
    "# Afficher le gradient de x (devrait rester le m√™me)\n",
    "print (x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch offre √©galement la possibilit√© d'effectuer les op√©rations des tensors sur CPU ou GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V√©rifier que vous avez la capacit√© d'ex√©cuter sur GPU sur votre machine\n",
    "dev = torch.device(\"gpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si vous avez GPU, vous pouvez d√©placer les calculs qu'on vient de faire sur GPU\n",
    "#dommage j'ai pas du GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Vous pouvez explorer d'autres op√©rations torch peuvent √™tre explor√©es ici: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Notre premier NN\n",
    "\n",
    "![image](resources/learning.png)\n",
    "\n",
    "Source: Deep Learning with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Dans notre TP, nous allons impl√©menter un feed forward NN qui identifie les chiffres √©crits √† la main (Hello World! des NN). La difficult√© revient √† identifier le m√™me chiffre m√™me s'il est √©crit d'une mani√®re tr√®s diff√©rente. \n",
    "\n",
    "Notre NN devra prendre en input une image (28 x 28 pixels) et identifier le chiffre en output. Le Dataset utilis√©, __MNIST__, englobe 60.000 √©chantillions de chiffres √©crits √† la main par 250 personnes pour l'apprentissage, et 10.000 pour le test √©crits par un autre groupe de 250 personnes. Les √©chantillons ont √©t√© rassembl√©s et merg√©s par NIST (United States' National Institute of Standards and Technology), d'o√π le nom du dataset. \n",
    "\n",
    "Pour ce faire, nous allons cr√©er un r√©seau de neurones qui permet de **classfier** une image selon un **output label**. \n",
    "\n",
    "- Combien de Labels faudrait-il pr√©voir en output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 (output)\n",
    "28*28 (input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les √©tapes pour la cr√©ation de notre NN sont les suivants:\n",
    "\n",
    "1. Lire et pr√©parer les donn√©es \n",
    "\n",
    "2. Cr√©er le r√©seau de neuronne\n",
    "\n",
    "3. Entra√Æner le r√©seau de neuronne\n",
    "\n",
    "4. Tester notre mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lire et pr√©parer les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PO-N2fynM53t"
   },
   "source": [
    "Avant d'impl√©menter tout mod√®le, il faut commencer par **Examiner et comprendre les donn√©es** puis les **formatter** convenablement pour alimenter le NN. L'objectif de cette partie est d'abord d'explorer le dataset MNIST, puis de pr√©parer les datasets input du NN.\n",
    "\n",
    "\n",
    "1.   Importer le MNIST dataset\n",
    "2.   Afficher les images avec leurs labels\n",
    "3.   Pr√©parer les donn√©es: split train, test, validation et normalisation des donn√©es\n",
    "4.   Cr√©er un Pytorch Dataset\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.   Importer le MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer la librairie torch et le module datasets de torchvision\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Le projet torchvision contient les meilleures architectures NN pour computer vision, ainsi que des datasets standards et utilitaires pour impl√©menter les projest computer vision. La liste des datasets du projet peut √™tre explor√©e ici: https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "Le dataset MNIST contient un sous dataset pour le training et un pour le test. R√©cup√©rer ces deux sous-dataset en deux objets dataset https://pytorch.org/docs/stable/torchvision/datasets.html#mnist\n",
    "\n",
    "N.B. Ne pas oublier de donner des noms significatifs √† vos variables.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les donn√©es d'apprentissage\n",
    "downloaded_train = datasets.MNIST(root='./resources', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les donn√©es de test\n",
    "downloaded_test = datasets.MNIST(root='./resources', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Essayons d'explorer les donn√©es dans nos datasets. MNIST devrait contenir des images de chiffres √©crits √† la main. Une image est repr√©sent√© comme un Tensor Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./resources\n",
      "    Split: Train\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./resources\n",
      "    Split: Test\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Afficher un datapoint de votre dataset d'apprentissage, sa forme, le type des donn√©es, les valeurs min et max. \n",
    "# Que repr√©sente les valeurs du Tensor √† votre avis?\n",
    "print(downloaded_train)\n",
    "print(downloaded_test)\n",
    "print(downloaded_train.data[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(downloaded_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(255, dtype=torch.uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(downloaded_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CenterCrop',\n",
       " 'ColorJitter',\n",
       " 'Compose',\n",
       " 'ConvertImageDtype',\n",
       " 'FiveCrop',\n",
       " 'GaussianBlur',\n",
       " 'Grayscale',\n",
       " 'Lambda',\n",
       " 'LinearTransformation',\n",
       " 'Normalize',\n",
       " 'PILToTensor',\n",
       " 'Pad',\n",
       " 'RandomAffine',\n",
       " 'RandomApply',\n",
       " 'RandomChoice',\n",
       " 'RandomCrop',\n",
       " 'RandomErasing',\n",
       " 'RandomGrayscale',\n",
       " 'RandomHorizontalFlip',\n",
       " 'RandomOrder',\n",
       " 'RandomPerspective',\n",
       " 'RandomResizedCrop',\n",
       " 'RandomRotation',\n",
       " 'RandomSizedCrop',\n",
       " 'RandomVerticalFlip',\n",
       " 'Resize',\n",
       " 'Scale',\n",
       " 'TenCrop',\n",
       " 'ToPILImage',\n",
       " 'ToTensor',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'functional',\n",
       " 'functional_pil',\n",
       " 'functional_tensor',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "#### 1.2.  Afficher les images avec leurs labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utiliserons imshow de matplotlib pour afficher un √©chantillon des donn√©es. Pensez √† √©galement afficher le label correspondant √† chaque image en utilisant l'attribut targets votre objet MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '9')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Afficher un √©chantillon des images du dataset d'apprentissage avec leurs labels respectifs \n",
    "\n",
    "plt.imshow(downloaded_train.data[4], cmap=\"gray\")\n",
    "plt.title(downloaded_train.targets[4].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "#### 1.3.  Pr√©parer les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Cr√©er un dataset de validation**\n",
    "\n",
    "Notre dataset contient les donn√©es d'apprentissage et de test, nous aurons √©galement besoin d'un dataset de validation. Pour ce faire, nous allons diviser notre dataset d'apprentissage de mani√®re √† d√©dier **10.000** data point √† la validation. \n",
    "\n",
    "Nous utiliserons la librairie scikit learn qui contient une fonction permettant de diviser les donn√©es d'une mani√®re tr√®s efficace. Pour plus de d√©tails, voir: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer la fonction de splitting des donn√©es de scikit learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er 4 tensors en r√©sultat du splitting: donn√©es d'apprentissage, donn√©es de validation, labels d'apprentissage, et labels de validation  \n",
    "train_data, validation_data, train_targets, validation_targets = train_test_split(downloaded_train.data, downloaded_train.targets, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les labels de test √† partir de votre sous-dataset de test\n",
    "test_data = downloaded_test.data\n",
    "test_targets = downloaded_test.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Vous devez maintenant avoir 6 tensors, un pour les donn√©es et l'autre pour les labels et ce pour l'apprentissage, le test, et la validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 28, 28]) torch.Size([50000])\n",
      "torch.Size([10000, 28, 28]) torch.Size([10000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# Afficher la taille de chaque tensor\n",
    "print(train_data.shape, train_targets.shape)\n",
    "print(validation_data.shape, validation_targets.shape)\n",
    "print(test_targets.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**Normaliser les donn√©es**\n",
    "\n",
    "Il est souvent recommand√© de normaliser les donn√©es avant d'alimenter le NN pour am√©liorer sa performance. On peut facilement redimensionner √† l'intervalle [0,1] les valeurs de nos donn√©es en utilisant la moyenne et la d√©viation standard suivant cette formule: $$(Data - Mean) / standard Deviation$$\n",
    "\n",
    "Comme \"thumb rule\", on normalise les donn√©es de test et de validation en utilisant la moyenne et la d√©viation des donn√©es d'apprentissage. Le raisonnement √©tant que les donn√©es test et validation sont indisponibles au moment de la cr√©ation du NN.   \n",
    "\n",
    "Apr√®s normalisation, le mean devrait √™tre 0 et standard deviation √† 1 (ou tr√®s proche resp. de 0 et 1).\n",
    "\n",
    "N.B. Il faudra convertir les valeurs de vos tensors en float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les valeurs des tensors en float\n",
    "train_data = train_data.float()\n",
    "test_data = test_data.float()\n",
    "validation_data = validation_data.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocker dans des variables la moyenne et la d√©viation standard des donn√©es d'apprentissage \n",
    "mean_train = torch.mean(train_data)\n",
    "std_train = torch.std(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les donn√©es d'apprentissage, de test, et de validation par ces valeurs\n",
    "train_data = (train_data - mean_train)/std_train\n",
    "test_data = (test_data - mean_train)/std_train\n",
    "validation_data = (validation_data - mean_train)/std_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.4224e-08) tensor(1.)\n",
      "tensor(0.0061) tensor(1.0078)\n",
      "tensor(0.0003) tensor(1.0005)\n"
     ]
    }
   ],
   "source": [
    "# Afficher la moyenne et la d√©viation standard de chaque dataset\n",
    "print(train_data.mean(), train_data.std())\n",
    "print(test_data.mean(),test_data.std())\n",
    "print(validation_data.mean(), validation_data.std())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "#### 1.4. Cr√©ation de Pytorch Dataset\n",
    "\n",
    "Notre Pipeline devrait commencer par le chargement des donn√©es dans le NN. Pytorch fournit un ensemble d'outils facilitant et optimisant cette t√¢che. La classe **Dataset** permet de cr√©er, sur la base de nos donn√©es, un dataset personalis√© qui pourra √™tre utilis√© par la suite par la fonction built-in **DataLoader** afin d'alimenter les donn√©es lors de l'entra√Ænement du NN. Dataset fournit un acc√®s uniforme √† nos donn√©es. DataLoader joue le r√¥le d'un data feeder en cr√©ant les batches de donn√©es qui fournissent au r√©seau de neuronne un √©chantillon de donn√©e √† chaque it√©ration.\n",
    "\n",
    "Documentation classe Dataset: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
    "\n",
    "Afin de cr√©er notre Pytorch Dataset personalis√©, nous allons h√©riter de la classe Dataset et red√©finir les fonctions suivantes:\n",
    "*   \\_\\_init__(self, data, targets): constructeur qui assignera les valeurs des attributs data et targets √† l'objet une fois instanci√©\n",
    "*   \\_\\_getitem__(self, idx) : permet de r√©cup√©rer l'item √† l'index idx. Utile pour √©viter de charger la totalit√© du Dataset en m√©moire (s'il est volumineux, on pr√©cise le chemin dans  \\_\\_init__), \n",
    "*   \\_\\_len__(self) : retroune la longeur de notre vecteur target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer Dataset de torch.utils.data\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une classe qui h√©rite de Dataset et red√©finit les m√©thodes comme susmentionn√©\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super(MyDataset, self)\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Nous allons instancier 3 objets (√† partir de votre classe personnalis√©e) pour les donn√©es et targets de l'apprentissage, test et validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les 3 objets en instantiant votre classe\n",
    "train_dataset = MyDataset(train_data, train_targets)\n",
    "test_dataset = MyDataset(test_data, test_targets)\n",
    "validation_dataset = MyDataset(validation_data, validation_targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer DataLoader de torch.utils.data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> DataLoader aide pour l'√©chantillonage et l'organisation de nos donn√©es en mini-batches. A chaque it√©ration d'apprentissage (epoch), le DataLoader fait un shuffling des donn√©es avant de les passer au NN. DataLoader prend le dataset et la taille du batch comme argument. On mettra pour l'instant une taille de 64.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une variable pour la taille du batch\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les objets DataLoader pour vos datasets d'apprentissage, test et validation en lui donner la taille du batch convenue\n",
    "\n",
    "train_DL = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_DL = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_DL = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quelle est la taille de vos objets dataLoader? Comment expliquer ces r√©sultats?\n",
    "len(train_DL) #50000/64 nbres des batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### 2. Cr√©er le r√©seau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch fournit le module nn qui comprend les classes repr√©sentant les briques de base pour construire un r√©seau de neurones. Il y a maintes mani√®res de cr√©er un NN sur Pytorch, nous allons explorer quelques unes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer le module nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Pytorch permet de concat√©ner des classes de notre choix pour la cr√©ation de notre NN, et ce gr√¢ce √† nn.Sequential(). Cette m√©thode prend les donn√©es en input, et se charge de faire passer les outputs interm√©diaires aux modules suivants, puis produit l'output du dernier module.\n",
    "\n",
    "Pour notre NN, nous allons cr√©er une architecture compos√©e de:\n",
    "\n",
    "1. Input Layer: Nos images ont une taille 28 x 28. On va essayer de r√©duire la taille en 64\n",
    "2. Fonction d'activation: ReLu\n",
    "3. Hidden Layer: applique une transformation lin√©aire sur les donn√©es en input, et r√©duit leur dimension en 32\n",
    "4. Fonction d'activation: ReLu\n",
    "5. Output Layer: applique une transformation lin√©aire sur les donn√©es en input, et r√©duit leur dimension en 10 (Nombre de classes)\n",
    "\n",
    "Le choix que nous venons de faire des nombres des neurones dans hidden Layer est al√©atoire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En utilisant Sequential(), cr√©er un mod√®le avec l'architecture susmentionn√©e\n",
    "layers = []\n",
    "layers.append(nn.Linear(784, 64))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(64, 32))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(32, 10))\n",
    "\n",
    "net = nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52650"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher le nombre de param√®tres qui seront entra√Æn√©s par le NN cr√©√©. Pourquoi ce chiffre?\n",
    "total = 0\n",
    "for p in net.parameters():\n",
    "    if p.requires_grad:\n",
    "        total += p.numel()\n",
    "total  #784*64 + 64*32 + 32*10 + 64 + 32 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Sequential est une fonction standard de Pytorch. Elle n'offre pas assez de marge de personalisation. C'est pour autant qu'on a tendance √† cr√©er nos propres classe de r√©seaux de neurones, en h√©ritant de la classe nn.Module et en red√©finissant ses m√©thodes.\n",
    "\n",
    "La cr√©ation de notre Classe r√©seau de neurones se fera en h√©ritant de nn.Module et en red√©finissant:\n",
    "1. La m√©thode \\_\\_init__ o√π on initialise les couches √† utiliser (on suivra la m√™me architecture que le premier NN)\n",
    "2. La m√©thode forward o√π on sp√©cifie les connexions entre les couches. Cela permet de pr√©ciser les op√©rations qu'on appliquera sur les donn√©es √† chaque passe (et leur passage de l'input, hidden, √† l'output layer).\n",
    "\n",
    "\n",
    "Dans la fonction forward, on utilisera le module **torch.nn.Functional** qui contient un ensemble de fonctions utiles comme les fonctions d'activation... Vous pouvez voir un exemple de d√©finition d'un NN personalis√© sur la documentation de pytorch: https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer torch.nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsXCHwP7RP0b"
   },
   "outputs": [],
   "source": [
    "# Cr√©er une classe qui h√©rite de nn.Module et red√©finir le constructeur ainsi que la m√©thode forward\n",
    "class Net (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancier votre NN\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52650"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V√©rifier que vous avez le m√™me nombre de param√®tres que le premier NN\n",
    "total = 0\n",
    "for p in net.parameters():\n",
    "    if p.requires_grad:\n",
    "        total += p.numel()\n",
    "total  #784*64 + 64*32 + 32*10 + 64 + 32 + 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### 3. Entra√Æner le r√©seau de neuronne\n",
    "\n",
    "Maintenant que nous avons notre r√©seau de neurones, on devra commencer √† l'entra√Æner. La boucle d'apprentissage est le processus qui permettra √† notre r√©seau de neurones d'apprendre √† partir des donn√©es input et d'ajuster les poids du NN selon les r√©sultats de la fonction Loss. Pour impl√©menter notre boucle d'apprentissage sur Pytorch, nous avons besoin de:\n",
    "\n",
    "1. Pr√©ciser un nombre d'it√©ration pour l'apprentissage (epochs)\n",
    "2. D√©finir notre fonction co√ªt\n",
    "3. Choisir l'optimiseur qui permettra d'optimiser le co√ªt\n",
    "\n",
    "    \n",
    "Notre boucle d'apprentissage se fera selon le nombre des epochs d√©fini, et devra comporter: \n",
    "1. Une boucle sur les donn√©es d'entra√Ænement via DataLoader (minibatch): Alimenter les donn√©es dans le NN, Calculer le co√ªt, et faire la backpropagation. \n",
    "2. Une boucle sur les donn√©es de validation via DataLoader:  Alimenter les donn√©es dans le NN, Calculer le co√ªt, calculer un score de pr√©cision du mod√®le (on va d√©finir un score simple qui indique le nombre de pr√©visions correctes).\n",
    "\n",
    "Une bonne pratique est d'afficher les valeurs de co√ªt et de pr√©cision pour chaque epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir la fonction du co√ªt. On peut choisir CrossEntropyLoss\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir une fonction d'optimisation des co√ªt: Adam par exemple. On devra d√©finir un learning rate. On choisira 0.001.\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir le nombre d'epochs. Commencer petit. \n",
    "epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.0111, validation loss: 0.1602, correct predictions: 97.06%\n",
      "epoch: 1, train loss: 0.0111, validation loss: 0.1778, correct predictions: 97.32%\n",
      "epoch: 2, train loss: 0.0106, validation loss: 0.1557, correct predictions: 97.47%\n",
      "epoch: 3, train loss: 0.0106, validation loss: 0.1766, correct predictions: 97.20%\n"
     ]
    }
   ],
   "source": [
    "# boucle d'apprentissage:\n",
    "for ep in range(epoch):\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    for data in train_DL:\n",
    "        feature, label = data\n",
    "        \n",
    "        output = net(torch.flatten(feature, start_dim=1))\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss +=  loss.item() #it's a tensor\n",
    "    \n",
    "    train_loss /= len(train_DL)\n",
    "        \n",
    "\n",
    "    # boucle de validation:\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in validation_DL:\n",
    "            feature, label = data\n",
    "\n",
    "            output = net(feature.view(-1, 28*28))\n",
    "\n",
    "            loss = loss_function(output, label)\n",
    "            valid_loss +=  loss.item()\n",
    "\n",
    "            correct += torch.sum(torch.argmax(output, dim=1) == label).item()\n",
    "\n",
    "        valid_loss /= len(validation_DL)\n",
    "        correct /= len(validation_DL.dataset) #10.000\n",
    "\n",
    "    print(f\"epoch: {ep}, train loss: {train_loss:.4f}, validation loss: {valid_loss:.4f}, correct predictions: {correct*100:.2f}%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### 4. Tester le mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Tester notre mod√®le revient √† calculer la pr√©cision de la m√™me mani√®re que nous avons fait tout √† l'heure, mais sur les donn√©es test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 97.20%\n"
     ]
    }
   ],
   "source": [
    "# boucle de test:\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for data in validation_DL:\n",
    "        feature, label = data\n",
    "        \n",
    "        output = net(feature.view(-1, 28*28))\n",
    "        \n",
    "        loss = loss_function (output, label)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        correct += torch.sum(torch.argmax(output, dim=1) == label).item()\n",
    "        \n",
    "\n",
    "    test_loss /= len(test_DL)\n",
    "    correct /= len(test_DL.dataset) #10.000  \n",
    "\n",
    "print(f\"Accuracy {correct*100:.2f}%\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(feature[0].view(28,28))\n",
    "plt.title(torch.argmax(net(feature[0].view(-1, 28*28))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BY BENDER & BENHIMA"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oLSMwg84dHjf"
   ],
   "name": "Coding AI - Intro to PyTorch - Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
